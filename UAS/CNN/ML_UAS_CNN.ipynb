{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hUu6Rg07NkZD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers, regularizers\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK0bzIiSOLGK",
        "outputId": "d9c44da9-f176-40b6-adc5-8d0eac9b67e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/FishImgDataset'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir   = os.path.join(base_dir, 'val')\n",
        "test_dir  = os.path.join(base_dir, 'test')\n",
        "\n",
        "print(\"Isi folder:\")\n",
        "print(os.listdir(base_dir))\n",
        "\n",
        "print(\"Isi folder TRAIN:\")\n",
        "print(os.listdir(os.path.join(base_dir, 'train')))\n",
        "\n",
        "print(\"Isi folder VAL:\")\n",
        "print(os.listdir(os.path.join(base_dir, 'val')))\n",
        "\n",
        "print(\"Isi folder TEST:\")\n",
        "print(os.listdir(os.path.join(base_dir, 'test')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdH_3l1cOU8S",
        "outputId": "e39799f5-38ec-4b4a-f1d6-586b4c5bef7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isi folder:\n",
            "['test', 'train', 'val']\n",
            "Isi folder TRAIN:\n",
            "['Goby', 'Black Spotted Barb', 'Bangus', 'Fourfinger Threadfin', 'Climbing Perch', 'Glass Perchlet', 'Big Head Carp', 'Catfish', 'Freshwater Eel', 'Jaguar Gapote', 'Long-Snouted Pipefish', 'Indian Carp', 'Janitor Fish', 'Gold Fish', 'Grass Carp', 'Green Spotted Puffer', 'Knifefish', 'Gourami', 'Indo-Pacific Tarpon', 'Perch', 'Pangasius', 'Mullet', 'Silver Barb', 'Snakehead', 'Scat Fish', 'Silver Perch', 'Mosquito Fish', 'Mudfish', 'Silver Carp', 'Tilapia', 'Tenpounder']\n",
            "Isi folder VAL:\n",
            "['Black Spotted Barb', 'Catfish', 'Freshwater Eel', 'Fourfinger Threadfin', 'Climbing Perch', 'Glass Perchlet', 'Bangus', 'Big Head Carp', 'Gold Fish', 'Jaguar Gapote', 'Janitor Fish', 'Indo-Pacific Tarpon', 'Grass Carp', 'Indian Carp', 'Goby', 'Green Spotted Puffer', 'Gourami', 'Knifefish', 'Mullet', 'Silver Perch', 'Silver Barb', 'Mosquito Fish', 'Pangasius', 'Perch', 'Long-Snouted Pipefish', 'Mudfish', 'Silver Carp', 'Scat Fish', 'Tilapia', 'Snakehead', 'Tenpounder']\n",
            "Isi folder TEST:\n",
            "['Glass Perchlet', 'Fourfinger Threadfin', 'Bangus', 'Gold Fish', 'Catfish', 'Climbing Perch', 'Goby', 'Black Spotted Barb', 'Big Head Carp', 'Freshwater Eel', 'Mosquito Fish', 'Green Spotted Puffer', 'Long-Snouted Pipefish', 'Grass Carp', 'Indian Carp', 'Jaguar Gapote', 'Janitor Fish', 'Gourami', 'Knifefish', 'Indo-Pacific Tarpon', 'Tenpounder', 'Mudfish', 'Snakehead', 'Silver Perch', 'Perch', 'Pangasius', 'Scat Fish', 'Silver Barb', 'Mullet', 'Silver Carp', 'Tilapia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = datagen.flow_from_directory(train_dir, target_size=image_size, batch_size=batch_size, class_mode='categorical')\n",
        "val_data = datagen.flow_from_directory(val_dir, target_size=image_size, batch_size=batch_size, class_mode='categorical')\n",
        "test_data = datagen.flow_from_directory(test_dir, target_size=image_size, batch_size=batch_size, class_mode='categorical', shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GexPe3j7OZ7y",
        "outputId": "5b64b3bb-0f86-4cbf-cd25-42c9917dc3d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8801 images belonging to 31 classes.\n",
            "Found 2751 images belonging to 31 classes.\n",
            "Found 1760 images belonging to 31 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Data Augmentation & Preprocessing\n",
        "import os\n",
        "\n",
        "image_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/FishImgDataset'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir   = os.path.join(base_dir, 'val')\n",
        "test_dir  = os.path.join(base_dir, 'test')\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_data = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# 3. CNN Model Architecture dengan L2 Regularization\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3), kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(64, (3,3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(128, (3,3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(train_data.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 4. Compile dengan Learning Rate Scheduler\n",
        "initial_lr = 0.001\n",
        "lr_schedule = callbacks.LearningRateScheduler(lambda epoch: initial_lr * (0.95 ** epoch))\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizers.Adam(learning_rate=initial_lr),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 5. Callbacks\n",
        "early_stop = callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "# 6. Training\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=30,\n",
        "    callbacks=[early_stop, lr_schedule]\n",
        ")\n",
        "\n",
        "# 7. Evaluation\n",
        "test_data.reset()\n",
        "pred = model.predict(test_data)\n",
        "pred_labels = np.argmax(pred, axis=1)\n",
        "true_labels = test_data.classes\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, pred_labels))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# 8. ROC & AUC\n",
        "if train_data.num_classes == 2:\n",
        "    auc = roc_auc_score(true_labels, pred[:,1])\n",
        "    fpr, tpr, _ = roc_curve(true_labels, pred[:,1])\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.title(f\"ROC Curve (AUC = {auc:.2f})\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"ROC Curve hanya berlaku untuk binary classification.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTcCxIzwOesy",
        "outputId": "2ba006ef-b71b-4be9-a6cf-a558f44eec77"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8801 images belonging to 31 classes.\n",
            "Found 2751 images belonging to 31 classes.\n",
            "Found 1760 images belonging to 31 classes.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.1302 - loss: 3.4706 "
          ]
        }
      ]
    }
  ]
}